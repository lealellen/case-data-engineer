# Assignment 1 

SoluÃ§Ã£o desenvolvida em PySpark para processamento e agregaÃ§Ã£o de dados.

---

## **Como executar o projeto no Databricks Community Edition**

### 1. FaÃ§a upload dos dados

- No menu Ã  esquerda, clique em **New**
- Clique em **Add or Upload Data** > **Upload files to a volume** > **All** > **default**
- Crie um volume com o nome "assignment-1"
- FaÃ§a upload do arquivo **info_transportes.csv**  
  - Caminho tÃ­pico: `/Volumes/workspace/default/assignment-1/info_transportes.csv`

### 3. Importe e execute o notebook

- Importe o notebook `pipeline_case_data_engineer.ipynb` para seu workspace Databricks
  - (VocÃª pode usar o arquivo disponÃ­vel neste repositÃ³rio)

 
  
## Acesse o notebook no Databricks

VocÃª pode visualizar ou clonar o notebook diretamente pela plataforma Databricks:

ðŸ‘‰ [Clique aqui para abrir o notebook no Databricks](https://dbc-dbfffb09-9678.cloud.databricks.com/editor/notebooks/2929827828570792?o=3068775036321311)

---

# Assignment 2
